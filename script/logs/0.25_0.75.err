/sfs/gpfs/tardis/project/uva_cv_lab/xuweic/SlowFast/tools/train_net.py:530: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=cfg.TRAIN.MIXED_PRECISION)
Resolving data files:   0%|          | 0/17 [00:00<?, ?it/s]Resolving data files: 100%|██████████| 17/17 [00:00<00:00, 19433.95it/s]
Resolving data files:   0%|          | 0/17 [00:00<?, ?it/s]Resolving data files: 100%|██████████| 17/17 [00:00<00:00, 19444.55it/s]
Resolving data files:   0%|          | 0/17 [00:00<?, ?it/s]Resolving data files: 100%|██████████| 17/17 [00:00<00:00, 16616.91it/s]
/sfs/gpfs/tardis/project/uva_cv_lab/xuweic/SlowFast/tools/train_net.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=cfg.TRAIN.MIXED_PRECISION):
[W127 15:48:42.401527515 Module.cpp:178] symbolizing C++ stack trace for exception; if this hangs, rerun with TORCH_DISABLE_ADDR2LINE=1...

Traceback (most recent call last):
  File "/sfs/gpfs/tardis/project/uva_cv_lab/xuweic/SlowFast/tools/run_net.py", line 51, in <module>
    main()
  File "/sfs/gpfs/tardis/project/uva_cv_lab/xuweic/SlowFast/tools/run_net.py", line 27, in main
    launch_job(cfg=cfg, init_method=args.init_method, func=train)
  File "/sfs/gpfs/tardis/project/uva_cv_lab/xuweic/SlowFast/slowfast/utils/misc.py", line 420, in launch_job
    func(cfg=cfg)
  File "/sfs/gpfs/tardis/project/uva_cv_lab/xuweic/SlowFast/tools/train_net.py", line 658, in train
    train_epoch(
  File "/sfs/gpfs/tardis/project/uva_cv_lab/xuweic/SlowFast/tools/train_net.py", line 153, in train_epoch
    scaler.scale(loss).backward()
  File "/home/rqa8sm/.local/lib/python3.11/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home/rqa8sm/.local/lib/python3.11/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/rqa8sm/.local/lib/python3.11/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 740.00 MiB. GPU 0 has a total capacity of 44.34 GiB of which 640.81 MiB is free. Including non-PyTorch memory, this process has 43.70 GiB memory in use. Of the allocated memory 42.25 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Exception raised from malloc at ../c10/cuda/CUDACachingAllocator.cpp:1318 (most recent call first):
C++ CapturedTraceback:
#4 std::_Function_handler<std::shared_ptr<c10::LazyValue<std::string> const> (), c10::SetStackTraceFetcher(std::function<std::string ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) from Logging.cpp:0
#5 c10::Error::Error(c10::SourceLocation, std::string) from ??:0
#6 c10::cuda::CUDACachingAllocator::Native::DeviceCachingAllocator::malloc(signed char, unsigned long, CUstream_st*) from CUDACachingAllocator.cpp:0
#7 c10::cuda::CUDACachingAllocator::Native::NativeCachingAllocator::malloc(void**, signed char, unsigned long, CUstream_st*) from :0
#8 c10::cuda::CUDACachingAllocator::Native::NativeCachingAllocator::allocate(unsigned long) from :0
#9 at::TensorBase at::detail::_empty_generic<long>(c10::ArrayRef<long>, c10::Allocator*, c10::DispatchKeySet, c10::ScalarType, std::optional<c10::MemoryFormat>) from :0
#10 at::detail::empty_generic(c10::ArrayRef<long>, c10::Allocator*, c10::DispatchKeySet, c10::ScalarType, std::optional<c10::MemoryFormat>) from ??:0
#11 at::detail::empty_cuda(c10::ArrayRef<long>, c10::ScalarType, std::optional<c10::Device>, std::optional<c10::MemoryFormat>) from ??:0
#12 at::detail::empty_cuda(c10::ArrayRef<long>, std::optional<c10::ScalarType>, std::optional<c10::Layout>, std::optional<c10::Device>, std::optional<bool>, std::optional<c10::MemoryFormat>) from ??:0
#13 at::detail::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&) from ??:0
#14 at::(anonymous namespace)::create_out(c10::ArrayRef<long>, c10::ArrayRef<long>, c10::TensorOptions const&) from RegisterCUDA.cpp:0
#15 at::(anonymous namespace)::structured_mm_out_cuda_functional::set_output_raw_strided(long, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::TensorOptions, c10::ArrayRef<at::Dimname>) from RegisterCUDA.cpp:0
#16 at::meta::structured_mm::meta(at::Tensor const&, at::Tensor const&) from ??:0
#17 at::(anonymous namespace)::wrapper_CUDA_mm(at::Tensor const&, at::Tensor const&) from RegisterCUDA.cpp:0
#18 c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<at::Tensor (at::Tensor const&, at::Tensor const&), &at::(anonymous namespace)::wrapper_CUDA_mm>, at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&> >, at::Tensor (at::Tensor const&, at::Tensor const&)>::call(c10::OperatorKernel*, c10::DispatchKeySet, at::Tensor const&, at::Tensor const&) from RegisterCUDA.cpp:0
#19 at::_ops::mm::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&) from ??:0
#20 torch::autograd::VariableType::(anonymous namespace)::mm(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&) from VariableType_3.cpp:0
#21 c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<at::Tensor (c10::DispatchKeySet, at::Tensor const&, at::Tensor const&), &torch::autograd::VariableType::(anonymous namespace)::mm>, at::Tensor, c10::guts::typelist::typelist<c10::DispatchKeySet, at::Tensor const&, at::Tensor const&> >, at::Tensor (c10::DispatchKeySet, at::Tensor const&, at::Tensor const&)>::call(c10::OperatorKernel*, c10::DispatchKeySet, at::Tensor const&, at::Tensor const&) from VariableType_3.cpp:0
#22 at::_ops::mm::call(at::Tensor const&, at::Tensor const&) from ??:0
#23 torch::autograd::generated::details::mm_mat1_backward(at::Tensor const&, at::Tensor const&, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::Layout, c10::Scalar const&) from :0
#24 torch::autograd::generated::AddmmBackward0::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) from ??:0
#25 torch::autograd::Node::operator()(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) from :0
#26 torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) from ??:0
#27 torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) from ??:0
#28 torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) from ??:0
#29 torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) from ??:0
#30 execute_native_thread_routine from thread48.o:0
#31 start_thread from ??:0
#32 __GI___clone from :0

